{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../data/train/dog'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m dog_subfolder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get a list of all dog image file names\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m dog_image_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdog_subfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the first nine dog images\u001b[39;00m\n\u001b[1;32m     13\u001b[0m dog_images \u001b[38;5;241m=\u001b[39m []\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train/dog'"
                    ]
                }
            ],
            "source": [
                "# Import and Check first 9 Dog Pictures (from the training set)\n",
                "\n",
                "# Path to the directory containing your image data\n",
                "train_dir = \"../data/train\"\n",
                "\n",
                "# Get a list of all dog image file names\n",
                "dog_subfolder = os.path.join(train_dir, \"dog\")\n",
                "\n",
                "# Get a list of all dog image file names\n",
                "dog_image_files = os.listdir(dog_subfolder)\n",
                "\n",
                "# Load the first nine dog images\n",
                "dog_images = []\n",
                "for i in range(9):\n",
                "    img_path = os.path.join(dog_subfolder, dog_image_files[i])\n",
                "    img = image.load_img(img_path)  # Adjust target_size as needed\n",
                "    img_array = image.img_to_array(img)\n",
                "    img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
                "    dog_images.append(img_array)\n",
                "\n",
                "# Create a single figure to display all nine images\n",
                "plt.figure(figsize=(12, 8))\n",
                "\n",
                "for i in range(9):\n",
                "    plt.subplot(3, 3, i + 1)\n",
                "    plt.imshow(dog_images[i])\n",
                "    plt.title('Dog Image')\n",
                "    plt.axis('off')\n",
                "\n",
                "# Adjust Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the pictures\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../data/train/cat'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m cats_subfolder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get a list of all Cat image file names\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m cats_image_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcats_subfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the first nine cat images\u001b[39;00m\n\u001b[1;32m     10\u001b[0m cats_images \u001b[38;5;241m=\u001b[39m []\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train/cat'"
                    ]
                }
            ],
            "source": [
                "# Import and Check first 9 Cat Pictures\n",
                "\n",
                "# Get a list of all cat image file names\n",
                "cats_subfolder = os.path.join(train_dir, \"cat\")\n",
                "\n",
                "# Get a list of all Cat image file names\n",
                "cats_image_files = os.listdir(cats_subfolder)\n",
                "\n",
                "# Load the first nine cat images\n",
                "cats_images = []\n",
                "for i in range(min(9, len(cats_image_files))):  # Limit to available cat images\n",
                "    img_path = os.path.join(cats_subfolder, cats_image_files[i])\n",
                "    img = image.load_img(img_path)\n",
                "    img_array = image.img_to_array(img)\n",
                "    img_array /= 255.0\n",
                "    cats_images.append(img_array)\n",
                "\n",
                "# Create a single figure to display all cat images\n",
                "plt.figure(figsize=(12, 8))\n",
                "\n",
                "for i in range(len(cats_images)):\n",
                "    plt.subplot(3, 3, i + 1)\n",
                "    plt.imshow(cats_images[i])\n",
                "    plt.title('Cat Image')\n",
                "    plt.axis('off')\n",
                "\n",
                "# Adjust Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the pictures\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 0 images belonging to 2 classes.\n",
                        "Found 0 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "# Define a few rules for DataGen and creating the Images train and test sets\n",
                "\n",
                "image_size = (224, 224)\n",
                "\n",
                "datagentrain = ImageDataGenerator()\n",
                "datagentest = ImageDataGenerator()\n",
                "\n",
                "# Train Data Generation\n",
                "train_data = datagentrain.flow_from_directory(\n",
                "    train_dir,\n",
                "    target_size = image_size,\n",
                "    classes = [\"dog\", \"cat\"] \n",
                ")\n",
                "\n",
                "# Test directory\n",
                "test_dir = \"../data/test\"\n",
                "\n",
                "# Test Data Generation\n",
                "test_data = datagentest.flow_from_directory(\n",
                "    test_dir,\n",
                "    target_size = image_size,\n",
                "    classes = [\"dog\", \"cat\"] \n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üìù Instructions\n",
                "\n",
                "Image classification system\n",
                "The dataset is composed of dog and cat photos provided as a subset of photos from a much larger 3 million manually annotated photos. This data was obtained through a collaboration between Petfinder.com and Microsoft.\n",
                "\n",
                "The data set was originally used as a CAPTCHA, i.e., a task that a human is believed to find trivial, but that a machine cannot solve, which is used on websites to distinguish between human users and bots. The task was named \"Asirra\". When \"Asirra\" was introduced, it was mentioned \"that user studies indicate that humans can solve it 99.6% of the time in less than 30 seconds.\" Barring a breakthrough in computer vision, we expect that computers will have no more than a 1/54,000 chance of solving it.\n",
                "\n",
                "At the time the competition was published, the state-of-the-art result was achieved with an SVM and was described in a 2007 paper with the title \"Machine Learning Attacks against Asirra's CAPTCHA\" (PDF) that achieved 80% classification accuracy. It was this paper that showed that the task was no longer a suitable task for a CAPTCHA shortly after the task was proposed.\n",
                "\n",
                "Step 1: Loading the dataset\n",
                "The dataset is located in Kaggle and you will need to access it to download it. You can find the competition here (or by copying and pasting the following link in your browser: https://www.kaggle.com/c/dogs-vs-cats/data)\n",
                "\n",
                "Download the datatset folder and unzip the files. You will now have a folder called train containing 25,000 image files (.jpg format) of dogs and cats. The pictures are labeled by their file name, with the word dog or cat.\n",
                "\n",
                "Step 2: Visualize the input information\n",
                "The first step when faced with a picture classification problem is to get as much information as possible through the pictures. Therefore, load and print the first nine pictures of dogs in a single figure. Repeat the same for cats. You can see that the pictures are in color and have different shapes and sizes.\n",
                "\n",
                "This variety of sizes and formats must be sorted out before entering the model. Make sure they all have a fixed size of 200x200 pixels.\n",
                "\n",
                "As you can see, there are a lot of images, make sure you follow the following rules:\n",
                "\n",
                "If you have more than 12 gigabytes of RAM, use the Keras image processing API to load the 25,000 photos into the training dataset and reshape them to 200√ó200 pixel square photos. The label must also be determined for each photo based on the file names. A tuple of photos and labels should be saved.\n",
                "If you have no more than 12 gigabytes of RAM, load the images progressively using the Keras ImageDataGenerator class and the flow_from_directory() function. This will be slower to run but will run on less capable hardware. This function prefers the data to be split into separate train/ and test/ directories, and under each directory to have a subdirectory for each class.\n",
                "Once you have all the images processed, create an ImageDataGenerator object for training and test data. Then pass the folder that has training data to the trdata object and, similarly, pass the folder that has test data to the tsdata object. In this way, the images will be automatically labeled and everything will be ready to enter the network.\n",
                "\n",
                "Step 3: Build an ANN\n",
                "Any classifier that fits this problem will have to be robust because some images show the cat or dog in a corner or perhaps 2 cats or dogs in the same picture. If you have been able to research some of the winner implementations of other competitions also related to images, you will see that VGG16 is a CNN architecture used to win the Kaggle ILSVR (Imagenet) competition in 2014. It is considered one of the best performing vision model architectures to date.\n",
                "\n",
                "It uses the following test architecture:\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))\n",
                "The above code applies convolutions to the data (Conv2D and MaxPool2D layers) and then applies dense layers (Dense layers) for processing the numerical values obtained after the convolutions.\n",
                "\n",
                "Then add the remaining elements to form the model, train it and measure its performance.\n",
                "\n",
                "Step 4: Optimize the above model\n",
                "Import the ModelCheckpoint and EarlyStopping method from Keras. Create an object of both and pass them as callback functions to fit_generator.\n",
                "\n",
                "Load the best model from the above and use the test set to make predictions.\n",
                "\n",
                "Step 5: Save the model\n",
                "Store the model in the corresponding folder."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Alex Arnold Notes (Slack)\n",
                "\n",
                "\n",
                "Documentation on the fit function in Keras:\n",
                "https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
                "\n",
                "In order to plot the loss, accuracy, etc. and use it to check for overfitting, underfitting, etc. one needs to also have validation data.\n",
                "Make sure to save the fit output as a variable (here we call it hist)\n",
                "\n",
                "One can tell the fit function to make an automatic split of the data and use part of this split as the validation data by\n",
                "specifying a validation_split value between 0 and 1 (what fraciton of the training data one wishes to use for validation.\n",
                "hist = model.fit(X_train, y_train, batch_size = <..>, epochs = <..>, ..., validation_split = <..>)\n",
                "\n",
                "Or, if one has explicitly made the validation data X_valid y_valid via splitting the data oneself, then you can also input the validation data via\n",
                "hist = model.fit(X_train, y_train, batch_size = <..>, epochs = <..>, ..., validation_data = (X_valid, y_valid))\n",
                "\n",
                "If one wishes to then grab the losses or accuracies that were calculated for the training and validation sets during the training session one can do\n",
                "training_loss = hist.history[\"loss\"]\n",
                "validation_loss = hist.history[\"val_loss\"]\n",
                "and/or\n",
                "training_loss = hist.history[\"accuracy\"]\n",
                "validation_loss = hist.history[\"val_accuracy\"]\n",
                "\n",
                "One can then plot these, e.g.\n",
                "plt.plot(training_loss, c='C0')\n",
                "plt.plot(validation_loss, c='C1')\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "\n",
                "TensorFlowTensorFlow\n",
                "tf.keras.Model  |  TensorFlow v2.16.1\n",
                "A model grouping layers into an object with training/inference features."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
